{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Grammar-checker-bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c78c6258a9254d9e8b911c29ef507950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3516ef98f231472b8767f07350af5a02",
              "IPY_MODEL_2dc9d415167d43339bbce76bcda92dd9",
              "IPY_MODEL_ef421ad1628d45838fa988863d3a6f6a"
            ],
            "layout": "IPY_MODEL_66de725705f34077a0e16df0f410846d"
          }
        },
        "3516ef98f231472b8767f07350af5a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fc3b704231642ceae4862ede76923a2",
            "placeholder": "​",
            "style": "IPY_MODEL_85c83098c70e4fbf8d2ef2c720838448",
            "value": "Downloading: 100%"
          }
        },
        "2dc9d415167d43339bbce76bcda92dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69deca85fac748288c1bc032d0e6fef4",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0402b1ebe4c640c3883331b2105de3f3",
            "value": 231508
          }
        },
        "ef421ad1628d45838fa988863d3a6f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_048b46b41a3a46018500ab8191dbd7d7",
            "placeholder": "​",
            "style": "IPY_MODEL_e35aed2942cc40f98f4dba1e16b86dca",
            "value": " 232k/232k [00:00&lt;00:00, 802kB/s]"
          }
        },
        "66de725705f34077a0e16df0f410846d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc3b704231642ceae4862ede76923a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85c83098c70e4fbf8d2ef2c720838448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69deca85fac748288c1bc032d0e6fef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0402b1ebe4c640c3883331b2105de3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "048b46b41a3a46018500ab8191dbd7d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e35aed2942cc40f98f4dba1e16b86dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f7e596c40714de28bdaf8bf6b6c8251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a21862c2bebb4de9b940184a01295cc9",
              "IPY_MODEL_aab60c7114c146afafd8352ff0f02e45",
              "IPY_MODEL_7ae656a8be6049748a6bd5ae31c8c3ea"
            ],
            "layout": "IPY_MODEL_4d7db49225f94ba098d005291d0176aa"
          }
        },
        "a21862c2bebb4de9b940184a01295cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d0edeb6cd524c4299e09af686cb5df9",
            "placeholder": "​",
            "style": "IPY_MODEL_e4f54edfb58d469094418abb7a04512a",
            "value": "Downloading: 100%"
          }
        },
        "aab60c7114c146afafd8352ff0f02e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a32ba69484224087bd432fbfcd194727",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fac045f3f1c14cdea4bd0aa7f56c67d2",
            "value": 570
          }
        },
        "7ae656a8be6049748a6bd5ae31c8c3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d12aa844b544738be62864f14f5b0b",
            "placeholder": "​",
            "style": "IPY_MODEL_6e6faea2a28948338be6e3aa5673fa62",
            "value": " 570/570 [00:00&lt;00:00, 7.16kB/s]"
          }
        },
        "4d7db49225f94ba098d005291d0176aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d0edeb6cd524c4299e09af686cb5df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f54edfb58d469094418abb7a04512a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a32ba69484224087bd432fbfcd194727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac045f3f1c14cdea4bd0aa7f56c67d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18d12aa844b544738be62864f14f5b0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e6faea2a28948338be6e3aa5673fa62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b14a50ad6314b0e84d14e086c434b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b10b1dd47b4d4e1fb557b88f5d2db33d",
              "IPY_MODEL_35cab25bb44f45b4a32e6e166fcc1181",
              "IPY_MODEL_34e84060c60e4b95b0d829e7a6021549"
            ],
            "layout": "IPY_MODEL_75b55dd05b104d99a9ec5852000b078f"
          }
        },
        "b10b1dd47b4d4e1fb557b88f5d2db33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_367bac5737a044c38a747202a639218c",
            "placeholder": "​",
            "style": "IPY_MODEL_dee54c331a3241bf99e5407672d7c7b8",
            "value": "Downloading: 100%"
          }
        },
        "35cab25bb44f45b4a32e6e166fcc1181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52ca246516bc4272bd3227676c1cbb9d",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea418180599f430d84759451809132f5",
            "value": 440473133
          }
        },
        "34e84060c60e4b95b0d829e7a6021549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da6547e436242a189f521f7db53d7a0",
            "placeholder": "​",
            "style": "IPY_MODEL_2e008024cd4e4877aafe5be69b3eb291",
            "value": " 440M/440M [00:16&lt;00:00, 33.6MB/s]"
          }
        },
        "75b55dd05b104d99a9ec5852000b078f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "367bac5737a044c38a747202a639218c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee54c331a3241bf99e5407672d7c7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52ca246516bc4272bd3227676c1cbb9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea418180599f430d84759451809132f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4da6547e436242a189f521f7db53d7a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e008024cd4e4877aafe5be69b3eb291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukulnag09/grammer-checker-using-bert/blob/main/Grammar_checker_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Grammar-checker\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "## Using Colab for Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0iOY8zvZzL"
      },
      "source": [
        "\n",
        "Google Colab offers free GPUs and TPUs! Since we'll be training a large neural network it's best to take advantage of this (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7BzqrVz2xjj"
      },
      "source": [
        "references:- https://towardsdatascience.com/checking-grammar-with-bert-and-ulmfit-1f59c718fe75"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "outputId": "832f9960-f619-4a1e-d221-36d6bdf7632c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "outputId": "064b4768-259e-4e26-eaca-7a117058637b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "## Installing the Hugging Face Library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N2UDLevYWn"
      },
      "source": [
        "\n",
        "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "outputId": "fc2a79f8-8623-41d4-e171-f6eef07454c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers==3.5.1\n",
        "!pip install torch==1.4.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==3.5.1 in /root/.local/lib/python3.7/site-packages (3.5.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (1.21.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (0.0.47)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (0.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (3.17.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (4.63.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (21.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.1) (0.1.91)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.1) (3.0.7)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.1) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.1) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.1) (1.1.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Downloading the Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ZKxKc04Btk"
      },
      "source": [
        "We'll use [The Corpus of Linguistic Acceptability (CoLA)](https://nyu-mll.github.io/CoLA/) dataset for single sentence classification. It's a set of sentences labeled as grammatically correct or incorrect. It was first published in May of 2018, and is one of the tests included in the \"GLUE Benchmark\" on which models like BERT are competing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZNVW6xd0T0X"
      },
      "source": [
        "We'll use the `wget` package to download the dataset to the Colab instance's file system. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be243ae-90b9-4572-e9be-a5feb8ed956e"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08pO03Ff1BjI"
      },
      "source": [
        "The dataset is hosted on GitHub in this repo: https://nyu-mll.github.io/CoLA/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMtmPMkBzrvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebaa430-092a-4377-91bd-fa7418571fdd"
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mKctx-ll2FB"
      },
      "source": [
        "Unzip the dataset to the file system. You can browse the file system of the Colab instance in the sidebar on the left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yv-tNv20dnH"
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "##  Parsing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYWzeGSY2xh3"
      },
      "source": [
        "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "b4a74a40-bf90-42d2-d231-8f2c353a8f71"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sentence_source  label label_notes  \\\n",
              "5017            ks08      1         NaN   \n",
              "4161            ks08      0           *   \n",
              "796             bc01      1         NaN   \n",
              "2871            l-93      1         NaN   \n",
              "1109            r-67      0           *   \n",
              "5589            c_13      1         NaN   \n",
              "704             bc01      1         NaN   \n",
              "95              gj04      0           *   \n",
              "2826            l-93      1         NaN   \n",
              "1845            r-67      0           *   \n",
              "\n",
              "                                    sentence  \n",
              "5017           The problem is easy to solve.  \n",
              "4161  Two miles are as far as they can walk.  \n",
              "796               Mary managed to go abroad.  \n",
              "2871    Herman mixed the eggs and the cream.  \n",
              "1109           I ran a man who was old down.  \n",
              "5589                        Doug blew up it.  \n",
              "704    John spoke French to Mary intimately.  \n",
              "95           The ball wriggled itself loose.  \n",
              "2826        Paula spanked the naughty child.  \n",
              "1845                  We'll go together, us.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76eb32c0-5832-4ab1-a7e0-03b95c321892\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5017</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The problem is easy to solve.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4161</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Two miles are as far as they can walk.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mary managed to go abroad.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2871</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Herman mixed the eggs and the cream.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1109</th>\n",
              "      <td>r-67</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>I ran a man who was old down.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5589</th>\n",
              "      <td>c_13</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Doug blew up it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>704</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John spoke French to Mary intimately.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>gj04</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>The ball wriggled itself loose.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2826</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Paula spanked the naughty child.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>r-67</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>We'll go together, us.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76eb32c0-5832-4ab1-a7e0-03b95c321892')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76eb32c0-5832-4ab1-a7e0-03b95c321892 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76eb32c0-5832-4ab1-a7e0-03b95c321892');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfWzpPi92UAH"
      },
      "source": [
        "The two properties we actually care about are the the `sentence` and its `label`, which is referred to as the \"weather it is grammatically correct or not\" (0=unacceptable, 1=acceptable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Let's extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5"
      },
      "source": [
        "## BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2"
      },
      "source": [
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c78c6258a9254d9e8b911c29ef507950",
            "3516ef98f231472b8767f07350af5a02",
            "2dc9d415167d43339bbce76bcda92dd9",
            "ef421ad1628d45838fa988863d3a6f6a",
            "66de725705f34077a0e16df0f410846d",
            "4fc3b704231642ceae4862ede76923a2",
            "85c83098c70e4fbf8d2ef2c720838448",
            "69deca85fac748288c1bc032d0e6fef4",
            "0402b1ebe4c640c3883331b2105de3f3",
            "048b46b41a3a46018500ab8191dbd7d7",
            "e35aed2942cc40f98f4dba1e16b86dca"
          ]
        },
        "outputId": "ada8c8f9-d7fa-4867-c119-43f2756e156c"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c78c6258a9254d9e8b911c29ef507950"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb638462-5555-4f38-d25c-a616ef39cd43"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ"
      },
      "source": [
        "## Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d153794-4fe1-4154-d11d-e495e2d1a8b4"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "\n",
        "import torch\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "## Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06"
      },
      "source": [
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99337c32-bd4e-48fb-d6bd-252fc5074b17"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "## Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sjzRT1V0zwm"
      },
      "source": [
        "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYitPoE-cjH"
      },
      "source": [
        "\n",
        "\n",
        "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "0f7e596c40714de28bdaf8bf6b6c8251",
            "a21862c2bebb4de9b940184a01295cc9",
            "aab60c7114c146afafd8352ff0f02e45",
            "7ae656a8be6049748a6bd5ae31c8c3ea",
            "4d7db49225f94ba098d005291d0176aa",
            "9d0edeb6cd524c4299e09af686cb5df9",
            "e4f54edfb58d469094418abb7a04512a",
            "a32ba69484224087bd432fbfcd194727",
            "fac045f3f1c14cdea4bd0aa7f56c67d2",
            "18d12aa844b544738be62864f14f5b0b",
            "6e6faea2a28948338be6e3aa5673fa62",
            "8b14a50ad6314b0e84d14e086c434b37",
            "b10b1dd47b4d4e1fb557b88f5d2db33d",
            "35cab25bb44f45b4a32e6e166fcc1181",
            "34e84060c60e4b95b0d829e7a6021549",
            "75b55dd05b104d99a9ec5852000b078f",
            "367bac5737a044c38a747202a639218c",
            "dee54c331a3241bf99e5407672d7c7b8",
            "52ca246516bc4272bd3227676c1cbb9d",
            "ea418180599f430d84759451809132f5",
            "4da6547e436242a189f521f7db53d7a0",
            "2e008024cd4e4877aafe5be69b3eb291"
          ],
          "height": 1000
        },
        "outputId": "f4eedd55-8ea1-463d-ab4c-5884887e3819"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f7e596c40714de28bdaf8bf6b6c8251"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b14a50ad6314b0e84d14e086c434b37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Jv6c7-HHDW"
      },
      "source": [
        "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
        "\n",
        "In the below cell, I've printed out the names and dimensions of the weights for:\n",
        "\n",
        "1. The embedding layer.\n",
        "2. The first of the twelve transformers.\n",
        "3. The output layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a20ee0f0-03a7-4bea-a7e7-007662060030"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
        "\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 4 (we'll see that this is probably too many...)\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## Training our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3"
      },
      "source": [
        "Helper function for formatting elapsed times as `hh:mm:ss`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N"
      },
      "source": [
        "We're ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33eb1587-b497-47b8-e57a-d9bb96b762a9"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Just right before the actual usage\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "...\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:53.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:20.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:46.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:14.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:40.\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:02:41\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:27.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:53.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:20.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:46.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:13.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:39.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:02:40\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.38\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:53.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:19.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:46.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:12.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:38.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:02:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.44\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:26.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:53.\n",
            "  Batch   120  of    241.    Elapsed: 0:01:19.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:46.\n",
            "  Batch   200  of    241.    Elapsed: 0:02:12.\n",
            "  Batch   240  of    241.    Elapsed: 0:02:38.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:02:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.50\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:11:01 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "14bb7543-16b3-4bbf-d462-31824c9755df"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.50         0.43           0.80       0:02:41         0:00:06\n",
              "2               0.32         0.38           0.85       0:02:40         0:00:06\n",
              "3               0.20         0.44           0.85       0:02:39         0:00:06\n",
              "4               0.15         0.50           0.85       0:02:39         0:00:06"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b85bc3b-b677-4e20-8717-4b5aba06e92e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:02:41</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:02:40</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:02:39</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:02:39</td>\n",
              "      <td>0:00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b85bc3b-b677-4e20-8717-4b5aba06e92e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b85bc3b-b677-4e20-8717-4b5aba06e92e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b85bc3b-b677-4e20-8717-4b5aba06e92e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Notice that, while the the training loss is going down with each epoch, the validation loss is increasing! This suggests that we are training our model too long, and it's over-fitting on the training data. \n",
        "\n",
        "(For reference, we are using 7,695 training samples and 856 validation samples).\n",
        "\n",
        "Validation Loss is a more precise measure than accuracy, because with accuracy we don't care about the exact output value, but just which side of a threshold it falls on. \n",
        "\n",
        "If we are predicting the correct answer, but with less confidence, then validation loss will catch this, while accuracy will not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "6e8007cd-488a-43c4-8c54-965d125c381e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "## Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DosV94BYIYxg"
      },
      "source": [
        "Now we'll load the holdout dataset and prepare inputs just as we did with the training set. Then we'll evaluate predictions using [Matthew's correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) because this is the metric used by the wider NLP community to evaluate performance on CoLA. With this metric, +1 is the best score, and -1 is the worst score. This way, we can see how well we perform against the state of the art models for this specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6aa9d7-f25f-4579-9194-a5f4f0391ac8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "##  Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed190e4d-25a9-495a-df80-7aea9866bc04"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f32c87d-0a22-48dd-8556-045b0ef6ab22"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0600a6f0-bcf0-472a-d243-b826f21bc706"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUM0UA1qJaVB"
      },
      "source": [
        "The final score will be based on the entire test set, but let's take a look at the scores on the individual batches to get a sense of the variability in the metric between batches. \n",
        "\n",
        "Each batch has 32 sentences in it, except the last batch which has only (516 % 32) = 4 test sentences in it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyfY1tqxU0t9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "9afc5486-960d-4f71-c0a7-a9b6da27aa33"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrjAPX2V-l4"
      },
      "source": [
        "Now we'll combine the results for all of the batches and calculate our final MCC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d1af766-c71c-4a41-ed8c-56f4c4a86cd5"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8"
      },
      "source": [
        "##  Saving & Loading Fine-Tuned Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe7112e-1965-4d1b-8edd-812cc7a46095"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to ./model_save/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0vstijw85SZ"
      },
      "source": [
        "The following functions will load the model back from disk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPZp77CiNCDj"
      },
      "source": [
        "## Import the saved model and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqLQT5i-C7V-"
      },
      "source": [
        "\n",
        "\n",
        "For running on our local machine(even CPU), we can just import the saved model and play with it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDoyjyA79C9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "647cad02-2640-4d51-d85e-00717944e062"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/model_save'\n",
        "\n",
        "print(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /root/.local/lib/python3.7/site-packages (3.5.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers) (3.17.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (3.0.7)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "/content/drive/MyDrive/model_save\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMJA-vA5yXhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beeb860d-358a-49d1-9620-5bf5406de61d"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvmqzSRvnQGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aadbc2d2-e399-4918-c8a2-00dd5e602a69"
      },
      "source": [
        "# Let's check it for a given sentence\n",
        "sent = \"you are doing good work\"\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "input_id = encoded_dict['input_ids']\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "attention_mask = encoded_dict['attention_mask']\n",
        "input_id = torch.LongTensor(input_id)\n",
        "attention_mask = torch.LongTensor(attention_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "p_cs-Uxvx7sb",
        "outputId": "ad216aa1-4443-4dba-ae3e-aa3995d3ff78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhF1-RCUt_vw"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_loaded = model_loaded.to(device)\n",
        "input_id = input_id.to(device)\n",
        "attention_mask = attention_mask.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c1trzncpdlr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5e940c-8414-4fed-e940-58b4738c8676"
      },
      "source": [
        "with torch.no_grad():\n",
        "  # Forward pass, calculate logit predictions\n",
        "  outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
        "\n",
        "logits = outputs[0]\n",
        "index = logits.argmax()\n",
        "if index == 1:\n",
        "  print(\"Gramatically correct\")\n",
        "  print(1)\n",
        "else:\n",
        "  print(\"Gramatically in-correct\")\n",
        "  print(0)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gramatically correct\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glE2YWqzzVn9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}